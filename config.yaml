# NeoChat 配置文件

# 调试与日志
debug:
  mode: False # 开启/关闭开发者模式。设置为True/False将开关Debug日志。

# 路径配置
paths:
  logs: "logs/run_logs"
  saves: "user_data/saves"
  story_packs: "data/story_packs"
  characters: "data/characters"
  player_characters: "data/player_characters"
  user_config: "user_data/user_config.json"

# RAG (Retrieval Augmented Generation) 设置
rag:
  enabled: false # 是否启用RAG功能 (当前为占位符)
  retrieval_count: 3
  context_m_before: 2
  context_n_after: 2

# LLM配置
llm:
  # 当前激活的 LLM 服务商。这里的名字必须与下面 providers 列表中的一个键匹配。
  active_provider: "deepseek_official"

  # API 请求的全局超时时间 (秒)
  timeout_seconds: 180

  # 对话历史长度限制
  conversation_history_limit: 50
  free_time_history_limit: 15
  ai_choice_history_context_count: 8
  conversation_settings:
    # 开启后，如果LLM的上下文中出现连续的多条"role: user"消息，它们会被自动合并为一条，内容用换行符分隔。
    merge_consecutive_user_messages: true

  # 服务商配置列表
  providers:
    # 1. DeepSeek 官方 API
    deepseek_official:
      type: "openai_compatible"
      api_key: "${DEEPSEEK_API_KEY}"
      base_url: "https://api.deepseek.com"
      api_path: "/chat/completions"
      default_model: "deepseek-chat"
      default_parameters:
        temperature: 0.7
        max_tokens: 4096

    # 2. 标准 OpenAI 接口
    openai_official:
      type: "openai_compatible"
      api_key: "${OPENAI_API_KEY}"
      base_url: "https://api.openai.com"
      api_path: "/v1/chat/completions"
      default_model: "gpt-4o"
      default_parameters:
        temperature: 0.7
        max_tokens: 4096

    # 3. Ollama (本地运行)
    ollama_local:
      type: "openai_compatible"
      api_key: "ollama"
      base_url: "http://localhost:11434"
      api_path: "/v1/chat/completions"
      default_model: "qwen2:7b"
      default_parameters:
        temperature: 0.8

    # 4. LM Studio (本地运行)
    lm_studio_local:
      type: "openai_compatible"
      api_key: "lm-studio"
      base_url: "http://localhost:1234"
      api_path: "/v1/chat/completions"
      default_model: "local-model"
      default_parameters:
        temperature: 0.7

    # 5. 阿里云百炼 (DashScope)
    aliyun_bailian:
      type: "openai_compatible"
      api_key: "${BAILIAN_API_KEY}"
      base_url: "https://dashscope.aliyuncs.com"
      api_path: "/api/v1/services/aigc/text-generation/generation"
      default_model: "qwen-turbo"
      default_parameters:
        temperature: 0.8

    # 6. 硅基流动 (SiliconFlow)
    siliconflow:
      type: "openai_compatible"
      api_key: "${SILICONFLOW_API_KEY}"
      base_url: "https://api.siliconflow.cn"
      api_path: "/v1/chat/completions"
      default_model: "deepseek-ai/deepseek-v2-chat"
      default_parameters:
        temperature: 0.7
        max_tokens: 8192

    # 7. 火山引擎 (VolcEngine)
    volcengine:
      type: "openai_compatible"
      api_key: "${VOLCENGINE_API_KEY}"
      base_url: "https://maas-api.ml-platform-cn-beijing.volces.com" # 以北京区域为例
      api_path: "/api/v1/chat/completions"
      default_model: "Skylark2-pro-4k"
      default_parameters:
        temperature: 0.7

    # 8. gemini 官方 API
    gemini_official:
      type: "gemini"
      api_key: "${GEMINI_API_KEY}"
      default_model: "gemini-2.5-flash"
      default_parameters:
        temperature: 0.7
        top_p: 1.0
        top_k: 32
        max_tokens: 8192